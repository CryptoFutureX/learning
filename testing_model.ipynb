{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55AC-AWKI8z"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b-H-OA6J4Cx"
      },
      "source": [
        "class CnnModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.vocab_size = 6002\r\n",
        "        self.embed_size = 100\r\n",
        "        self.num_filters = 100\r\n",
        "        self.filter_sizes = [3, 4, 5]\r\n",
        "        self.output_classes = 2\r\n",
        "        self.dropout = 0.8\r\n",
        "\r\n",
        "        # Embedding layer\r\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\r\n",
        "        self.convs = nn.ModuleList([\r\n",
        "                                    nn.Conv2d(\r\n",
        "                                        in_channels=1, \r\n",
        "                                        out_channels=self.num_filters,\r\n",
        "                                        kernel_size=(fs, self.embed_size)) \r\n",
        "                                    for fs in self.filter_sizes\r\n",
        "        ])\r\n",
        "        self.fc = nn.Linear(len(self.filter_sizes) * self.num_filters, self.output_classes)\r\n",
        "        self.dropout = nn.Dropout(self.dropout)\r\n",
        "\r\n",
        "    def forward(self, text, text_lengths):\r\n",
        "        embedded = self.embedding(text)\r\n",
        "        embedded = embedded.unsqueeze(1)\r\n",
        "\r\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\r\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\r\n",
        "\r\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\r\n",
        "        return self.fc(cat)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FdUyAJKIHB"
      },
      "source": [
        "model = CnnModel()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEY5vsweKZGa",
        "outputId": "2011e5a3-36c5-4151-f12c-2f2aa3ea8c4e"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Cryptofuture/cnn_sentiment_1.pt', map_location='cpu'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bntlU9CqK8o6",
        "outputId": "4d4d601d-08c7-429d-983f-e36adc0132ce"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f92f2cc0dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnIFHPaTLOaB"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "fh = open('/content/drive/MyDrive/Cryptofuture/text_vocab.pickle', 'rb');\r\n",
        "text = pickle.load(fh)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie6RzSJGZ5uc",
        "outputId": "a2a8a264-132b-4298-ce0a-2d3b455ebddf"
      },
      "source": [
        "text['hello'], len(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(791, 6002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoAMnHEHat8S",
        "outputId": "c3b69cb9-575a-4708-c80d-feeb81a64206"
      },
      "source": [
        "text['<pad>']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIyC9FTNaAeD"
      },
      "source": [
        "import spacy\r\n",
        "\r\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKAX3XMRaP8u"
      },
      "source": [
        "def predict_sentiment(model, tweet, min_length=10):\r\n",
        "    model.eval()\r\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)]\r\n",
        "    if len(tokenized) < min_length:\r\n",
        "        tokenized += ['<pad>'] * (min_length - len(tokenized))\r\n",
        "    indexed = [text[t] for t in tokenized]\r\n",
        "    tensor = torch.LongTensor(indexed).to('cpu')\r\n",
        "    tensor = tensor.unsqueeze(0)\r\n",
        "    prediction = torch.sigmoid(model(tensor, len(tensor)))\r\n",
        "    return prediction"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm4V4pApbAqU",
        "outputId": "34d88359-f2ba-45be-df8e-c8095d73e93f"
      },
      "source": [
        "predict_sentiment(model, 'Retweet if you\\'re putting your stimulus check in bitcoin')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1630, 0.7539]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAOzKKa3bDzl",
        "outputId": "eefa0534-5da1-4c8a-ad3a-f1f3bd65c623"
      },
      "source": [
        "predict_sentiment(model, 'Russell Okung announced in December he was converting half of his $13M salary into Bitcoin.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4738, 0.5171]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}